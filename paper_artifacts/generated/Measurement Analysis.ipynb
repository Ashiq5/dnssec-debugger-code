{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Result analysis\n",
    "\n",
    "You cannot run this as you have not our dataset file\n",
    "\n",
    "\n",
    "This jupyter notebook aim to parse and aggregate the result of our experiments.\n",
    "Due to our agreements with the data providers, we can neither provide the source of the experiment neither the results which contains proprietary data."
   ],
   "id": "96796877b03f1c0f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "eacbb9e2deed30ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T15:17:10.827147Z",
     "start_time": "2025-08-26T15:17:10.824427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import enum\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter"
   ],
   "id": "6ac4fce517190326",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Utility functions and class",
   "id": "36a751d4297260ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T15:17:10.849394Z",
     "start_time": "2025-08-26T15:17:10.841190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "FILEPATH_TO_DATASET = \"../.local/sanitized-and-merged-dnsviz.txt\"\n",
    "\n",
    "class instr_enum(enum.Enum):\n",
    "    SYNC_SERVERS = \"SYNC_SERVERS\"\n",
    "    GENERATE_KSK = \"GENERATE_KSK\"\n",
    "    GENERATE_ZSK = \"GENERATE_ZSK\"\n",
    "    GENERATE_KEY_PAIR = \"GENERATE_KEY_PAIR\"\n",
    "    GENERATE_DS = \"UPLOAD_DS\"\n",
    "    UPLOAD_DS = \"UPLOAD_DS\"\n",
    "    SIGN_PARENT = \"SIGN_PARENT\"\n",
    "    REMOVE_DS = \"REMOVE_DS\"\n",
    "    REVOKE_KEY = \"REMOVE_REVOKED_KEY\"\n",
    "    SIGN_ZONE = \"SIGN_ZONE\"\n",
    "    REGENERATE_DS = \"UPLOAD_DS\"\n",
    "    REDUCING_TTL = \"REDUCING_TTL\"\n",
    "\n",
    "class bind_cmd():\n",
    "    def __init__(self, cmd:instr_enum, priority:int):\n",
    "        self.cmd = cmd\n",
    "        self.priority = priority\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.cmd.value}_{self.priority}'\n",
    "\n",
    "def extract_instruction(gt_instrs):\n",
    "    res = list()\n",
    "    for i, instr in enumerate(gt_instrs):\n",
    "        if instr.startswith(\"Parent zone\"):\n",
    "            continue\n",
    "\n",
    "        elif \"Configure the erroneous servers to pull from the master\" in instr:\n",
    "            res.append(bind_cmd(instr_enum.SYNC_SERVERS, i))\n",
    "        elif \"Generate a new KSK key pair\" in instr:\n",
    "            res.append(bind_cmd(instr_enum.GENERATE_KSK, i))\n",
    "        elif \"Generate a new ZSK key pair\" in instr:\n",
    "            cmd = instr.split(\"BIND command: \")[1][1:-1]\n",
    "            res.append(bind_cmd(instr_enum.GENERATE_ZSK, i))\n",
    "        elif \"Generate a new key pair\" in instr:\n",
    "            res.append(bind_cmd(instr.GENERATE_KEY_PAIR, i))\n",
    "        elif \"Generate the corresponding DS record\" in instr:\n",
    "            res.append(bind_cmd(instr_enum.GENERATE_DS, i))\n",
    "        elif (\n",
    "            \"Upload DS record in the parent zone\" in instr\n",
    "            or \"Upload the DS record(s)\" in instr\n",
    "        ):\n",
    "            res.append(bind_cmd(instr_enum.UPLOAD_DS, i))\n",
    "        elif (\n",
    "            \"Remove the DS record(s)\" in instr\n",
    "            or \"Remove these extraneous DS record(s)\" in instr\n",
    "            or \"Remove these incorrect DS record(s)\" in instr  # tested\n",
    "        ):\n",
    "            res.append(bind_cmd(instr_enum.REMOVE_DS, i))\n",
    "        elif \"remove the revoked dnskey(s)\" in instr.lower():\n",
    "            res.append(bind_cmd(instr_enum.REVOKE_KEY, i))\n",
    "        elif \"Resign the zone\" in instr or \"Sign the zone\" in instr:\n",
    "            res.append(bind_cmd(instr_enum.SIGN_ZONE, i))\n",
    "        elif (\n",
    "            \"Resigning the zone should resolve the issue\" in instr\n",
    "            or \"Resigning the zone by explicitly setting the iteration count to 0\"\n",
    "            in instr\n",
    "        ):\n",
    "            res.append(bind_cmd(instr_enum.SIGN_ZONE, i))\n",
    "        elif \"resign the parent zone which should typically resolve the issue\" in instr:\n",
    "            res.append(bind_cmd(instr_enum.SIGN_ZONE, i))\n",
    "        elif \"Generate the correct DS record(s)\" in instr:\n",
    "            res.append(bind_cmd(instr_enum.REGENERATE_DS, i))\n",
    "        elif \"Upload the correct DS record(s)\" in instr:\n",
    "            res.append(bind_cmd(instr_enum.UPLOAD_DS, i))\n",
    "        elif \"Your record TTL is\" in instr and \"Your signature TTL is\" in instr:\n",
    "            pass\n",
    "        elif \"reducing your zone/record ttl\" in instr.lower():\n",
    "            res.append(bind_cmd(instr_enum.REDUCING_TTL, i))\n",
    "            res.append(bind_cmd(instr_enum.SIGN_ZONE, i))\n",
    "\n",
    "    return list(r.__str__() for r in res)"
   ],
   "id": "f8b94da3740ccf90",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T15:17:10.896965Z",
     "start_time": "2025-08-26T15:17:10.894400Z"
    }
   },
   "cell_type": "code",
   "source": "latex_export = dict()",
   "id": "e79e4697966bb4b1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T15:17:10.944883Z",
     "start_time": "2025-08-26T15:17:10.941191Z"
    }
   },
   "cell_type": "code",
   "source": "### Identical as src/utils/commons.py",
   "id": "90a6ecfbb97265a6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-26T15:17:11.004762Z",
     "start_time": "2025-08-26T15:17:10.994992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "KEY2ALGO_MAPPING = {\n",
    "    1: \"RSAMD5\",\n",
    "    3: \"DSASHA1\",\n",
    "    5: \"RSASHA1\",\n",
    "    6: \"DSANSEC3SHA1\",\n",
    "    7: \"NSEC3RSASHA1\",\n",
    "    8: \"RSASHA256\",\n",
    "    10: \"RSASHA512\",\n",
    "    13: \"ECDSAP256SHA256\",\n",
    "    14: \"ECDSAP384SHA384\",\n",
    "    15: \"ED25519\",\n",
    "    16: \"ED448\",\n",
    "}\n",
    "DEFAULT_ALGORITHM_TEXT = \"ECDSAP256SHA256\"\n",
    "DEFAULT_ALGORITHM_NUMBER = 13\n",
    "keysize_required_algorithms = {\n",
    "    \"RSAMD5\",\n",
    "    \"DSASHA1\",\n",
    "    \"RSASHA1\",\n",
    "    \"DSANSEC3SHA1\",\n",
    "    \"RSASHA1\",\n",
    "    \"NSEC3RSASHA1\",\n",
    "    \"RSASHA256\",\n",
    "    \"RSASHA512\",\n",
    "}\n",
    "CAT = {\n",
    "    \"DoE\": {\n",
    "        \"MISSING_NSEC_FOR_NODATA\",\n",
    "        \"MISSING_NSEC_FOR_NXDOMAIN\",\n",
    "        \"MISSING_NSEC_FOR_WILDCARD\",\n",
    "        \"NO_NSEC_MATCHING_SNAME\",\n",
    "        \"NO_NSEC3_MATCHING_SNAME\",\n",
    "        \"SNAME_COVERED\",\n",
    "        \"SNAME_NOT_COVERED\",\n",
    "        \"WILDCARD_COVERED\",\n",
    "        \"WILDCARD_NOT_COVERED\",\n",
    "        \"EXISTING_NAME_COVERED\",\n",
    "        \"INCONSISTENT_NXDOMAIN_ANCESTOR\",\n",
    "        \"NO_CLOSEST_ENCLOSER\",\n",
    "        \"NEXT_CLOSEST_ENCLOSER_NOT_COVERED\",\n",
    "        \"OPT_OUT_FLAG_NOT_SET\",\n",
    "        \"EXISTING_TYPE_NOT_IN_BITMAP\",\n",
    "        \"REFERRAL_WITHOUT_NS\",\n",
    "        \"REFERRAL_WITH_DS\",\n",
    "        \"REFERRAL_WITH_SOA\",\n",
    "        \"INVALID_NSEC3_HASH\",\n",
    "        \"INVALID_NSEC3_OWNER_NAME\",\n",
    "        \"LAST_NSEC_NEXT_NOT_ZONE\",\n",
    "        \"STYPE_IN_BITMAP\",\n",
    "        \"NONZERO_NSEC3_ITERATION_COUNT\",\n",
    "        \"UNSUPPORTED_NSEC3_ALGORITHM\",\n",
    "    },\n",
    "    \"RRSIG\": {\n",
    "        \"RRSIG_BAD_LENGTH_ECDSA256\",\n",
    "        \"RRSIG_BAD_LENGTH_ECDSA384\",\n",
    "        \"NO_SEP\",\n",
    "        \"SIGNER_NOT_ZONE\",\n",
    "        \"RRSIG_LABELS_EXCEED_RRSET_OWNER_LABELS\",\n",
    "        \"SIGNATURE_INVALID\",\n",
    "        \"MISSING_RRSIG\",\n",
    "        \"MISSING_RRSIG_FOR_ALG_DNSKEY\",\n",
    "        \"MISSING_RRSIG_FOR_ALG_DS\",\n",
    "    },\n",
    "    \"Server\": {\n",
    "        \"SERVER_UNRESPONSIVE_TCP\",\n",
    "        \"SERVER_UNRESPONSIVE_UDP\",\n",
    "        \"UNABLE_TO_RETRIEVE_DNSSEC_RECORDS\",\n",
    "        \"DNSSEC_DOWNGRADE_DO_CLEARED\",\n",
    "        \"DNSSEC_DOWNGRADE_EDNS_DISABLED\",\n",
    "        \"ERROR_WITH_EDNS\",\n",
    "        \"ERROR_WITH_EDNS_FLAG\",\n",
    "        \"ERROR_WITH_EDNS_OPTION\",\n",
    "        \"ERROR_WITHOUT_REQUEST_FLAG\",\n",
    "        \"RECURSION_NOT_AVAILABLE\",\n",
    "        \"SERVER_INVALID_RESPONSE_TCP\",\n",
    "        \"SERVER_INVALID_RESPONSE_UDP\",\n",
    "        \"NOT_AUTHORITATIVE\",\n",
    "        \"SERVER_NOT_AUTHORITATIVE\",\n",
    "        \"UPWARD_REFERRAL\",\n",
    "        \"REFERRAL_FOR_DS_QUERY\",\n",
    "    },\n",
    "    \"TTL\": {\n",
    "        \"ORIGINAL_TTL_EXCEEDED_RRSET\",\n",
    "        \"ORIGINAL_TTL_EXCEEDED_RRSIG\",\n",
    "        \"TTL_BEYOND_EXPIRATION\",\n",
    "    },\n",
    "    \"DNSKEY\": {\n",
    "        \"DNSKEY_REVOKED_RRSIG\",\n",
    "        \"DNSKEY_BAD_LENGTH_ECDSA256\",\n",
    "        \"DNSKEY_BAD_LENGTH_ECDSA384\",\n",
    "        \"DNSKEY_MISSING_FROM_SERVERS\",\n",
    "        \"DNSKEY_REVOKED_DS\",\n",
    "        \"DNSKEY_REVOKED_RRSIG\",\n",
    "        \"REVOKED_NOT_SIGNING\",\n",
    "        \"DNSKEY_ZERO_LENGTH\",\n",
    "        \"NO_TRUST_ANCHOR_SIGNING\",\n",
    "    },\n",
    "    \"Timing\": {\"INCEPTION_IN_FUTURE\", \"EXPIRATION_IN_PAST\"},\n",
    "    \"DS\": {\"MISSING_SEP_FOR_ALG\", \"DIGEST_INVALID\"},\n",
    "    \"NS\": set([]),\n",
    "    \"SOA\": set([]),\n",
    "    \"CNAME\": set([]),\n",
    "}\n",
    "\n",
    "DNSSECRelatedErrors = []\n",
    "for key in CAT:\n",
    "    if key == \"Server\":\n",
    "        continue\n",
    "    for err in CAT[key]:\n",
    "        if err == \"NO_TRUST_ANCHOR_SIGNING\" :\n",
    "            continue\n",
    "        DNSSECRelatedErrors.append(err)\n",
    "\n",
    "\n",
    "codes_to_ignore = CAT[\"Server\"]\n",
    "\n",
    "def data_from_line(line,src=\"\"):\n",
    "    js = json.loads(line)\n",
    "    intended = set(js.get(\"intended_errcodes\", [])).intersection(set(DNSSECRelatedErrors))\n",
    "    generated = set(js.get(\"generated_errcodes\", [])).intersection(set(DNSSECRelatedErrors))\n",
    "    exception = js.get(\"exception\", None)\n",
    "    diff = intended - generated - codes_to_ignore\n",
    "    if len(intended) == 0:\n",
    "        intended = None\n",
    "    if len(generated) == 0:\n",
    "        generated = None\n",
    "    if len(diff) == 0:\n",
    "        if exception is not None:\n",
    "            diff.add(\"EXCEPTION_IN_CODE\")\n",
    "        else:\n",
    "            diff = None\n",
    "    res =  {\"id\": int(js.get(\"id\")),\n",
    "                  \"name\" : js.get(\"zone_name\"),\n",
    "                  \"intended\" : sorted(list(intended)) if intended is not None else None,\n",
    "                  \"generated\": sorted(list(generated)) if generated is not None else None ,\n",
    "                  \"difference\" : sorted((list(diff))) if diff is not None else None,\n",
    "\n",
    "                    \"exceptions\": sorted(list(exception)) if exception is not None else None ,\n",
    "                  \"diff_str\":json.dumps(sorted(list(diff)) if diff is not None else []),\n",
    "                  \"number_of_steps_to_fix\": js.get(\"fix_itterations\", None),\n",
    "            \"src\":src\n",
    "            }\n",
    "    for i, fix in enumerate(js.get(\"fix_transition_errcodes\", [])):\n",
    "        res[f'after_fix_{i+1}'] = fix[\"errors_after_fix\"] if len(fix[\"errors_after_fix\"]) > 0 else None\n",
    "        fix = fix[\"fixes\"] if len(fix[\"fixes\"]) > 0 else None\n",
    "        cmd = list()\n",
    "        if fix is not None:\n",
    "            for j,d in enumerate(fix):\n",
    "                ins = d.get(\"instructions\", [])\n",
    "                cmd.extend([f\"{j}_{e}\" for e in extract_instruction(ins)])\n",
    "        sorted_by_fix_step = [ \"_\".join(e.split(\"_\")[1:]) for e in sorted(cmd, key=lambda x: int(x.split(\"_\")[0]))]\n",
    "        unique_sorted_by_fix_step = []\n",
    "        for e in sorted_by_fix_step:\n",
    "            if e not in unique_sorted_by_fix_step:\n",
    "                unique_sorted_by_fix_step.append(e)\n",
    "        sorted_by_cmd = [ \"_\".join(e.split(\"_\")[:-1]) for e in sorted(unique_sorted_by_fix_step, key=lambda x: int(x.split(\"_\")[-1]))]\n",
    "        executed_sort = []\n",
    "        for e in sorted_by_cmd:\n",
    "            if e not in executed_sort:\n",
    "                executed_sort.append(e)\n",
    "        if len(executed_sort) > 0:\n",
    "            res[f\"cmd_{i+1}\"] = str(executed_sort)\n",
    "    return res\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importing dataset results",
   "id": "31ce94092d9414c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T15:17:26.854786Z",
     "start_time": "2025-08-26T15:17:11.040530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datas = []\n",
    "nb_line = 0\n",
    "with open(FILEPATH_TO_DATASET) as f: # OK\n",
    "    for line in f:\n",
    "        datas.append(data_from_line(line, src=\"dnsviz-full\"))\n",
    "        nb_line += 1\n",
    "\n",
    "df = pd.DataFrame(datas)"
   ],
   "id": "c85a609d14254e5a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dataframe manipulations",
   "id": "67b1f57517126939"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T15:17:31.774303Z",
     "start_time": "2025-08-26T15:17:26.866878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df[\"generated_str\"] = df[\"generated\"].apply(lambda x : str(x))\n",
    "df[\"intended_str\"] =df[\"intended\"].apply(lambda x : str(x))\n",
    "df[\"cmd_1_str\"] = df[\"cmd_1\"].apply(lambda x : str(x))\n",
    "df[\"cmd_2_str\"] = df[\"cmd_2\"].apply(lambda x : str(x))\n",
    "df[\"cmd_3_str\"] = df[\"cmd_3\"].apply(lambda x : str(x))\n",
    "df[\"cmd_4_str\"] = df[\"cmd_4\"].apply(lambda x : str(x))\n",
    "#df.replace(\"['SYNC_SERVERS', 'SIGN_ZONE']\", \"['SIGN_ZONE', 'SYNC_SERVERS']\", inplace=True)\n",
    "\n",
    "# Those commands are the same, as whe sign zone when we remove a ds.\n",
    "\n",
    "df.replace(\"['REMOVE_DS', 'SIGN_ZONE']\", \"['REMOVE_DS']\", inplace=True)\n",
    "df.replace(\"['REMOVE_DS', 'SIGN_ZONE', 'SYNC_SERVERS']\", \"['REMOVE_DS', 'SYNC_SERVERS']\", inplace=True)\n",
    "\n",
    "df[\"only_nzic\"] = df[\"intended\"].apply(lambda x: False if x is None and str(x) != \"['NONZERO_NSEC3_ITERATION_COUNT']\" else True)\n",
    "df[\"not_only_nzic\"] = df[\"intended\"].apply(lambda x: True if x is not None and str(x) != \"['NONZERO_NSEC3_ITERATION_COUNT']\" else False)\n",
    "\n",
    "df_nzic_only = df[df[\"only_nzic\"] == True ]\n",
    "df_not_nzic_only = df[df[\"not_only_nzic\"] == True]"
   ],
   "id": "9b297d377e8aa4b4",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extracted information used in Dynamic Numbers",
   "id": "540a3f0243ff7f13"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extract simple numbers (not complex DataFrame manipulation)",
   "id": "ad26056cb4e82b18"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T15:17:34.338566Z",
     "start_time": "2025-08-26T15:17:31.791179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_with_error = df[df[\"intended\"].notna()][\"id\"].size\n",
    "total_with_generation = df[df[\"generated\"].notna()][\"id\"].size\n",
    "total_where_all_generated = df[(df[\"generated\"].notna()) & (df[\"difference\"].isna())][\"id\"].size\n",
    "total_with_error_nssic = df_not_nzic_only[\"id\"].size\n",
    "total_with_generation_nssic = df_not_nzic_only[(df_not_nzic_only[\"generated\"].notna())][\"id\"].size\n",
    "total_where_all_generated_nssic = df_not_nzic_only[(df_not_nzic_only[\"generated\"].notna()) & df_not_nzic_only[\"difference\"].isna()][\"id\"].size\n",
    "\n",
    "set_of_errors = set()\n",
    "for errors in df[df[\"intended\"].notna()][\"intended\"]:\n",
    "    for err in errors:\n",
    "        set_of_errors.add(err)\n",
    "\n",
    "set_of_generation_errors = set()\n",
    "for errors in df[df[\"generated\"].notna()][\"generated\"]:\n",
    "    for err in errors:\n",
    "        set_of_generation_errors.add(err)\n",
    "\n",
    "current_df = df\n",
    "\n",
    "cannot_fix_with_nzsic = current_df[(current_df[\"intended\"].notna()) &\n",
    "   ((current_df[\"difference\"].isna())) &\n",
    "    ( (current_df[\"cmd_1\"].isna()) |\n",
    "      (current_df[\"after_fix_1\"].notna()) & (current_df[\"cmd_2\"].isna()) |\n",
    "      (current_df[\"after_fix_2\"].notna()) & (current_df[\"cmd_3\"].isna()) |\n",
    "      (current_df[\"after_fix_3\"].notna()) & (current_df[\"cmd_4\"].isna()) |\n",
    "      (current_df[\"after_fix_4\"].notna())\n",
    "      )\n",
    "].shape[0]\n",
    "\n",
    "current_df = df_not_nzic_only\n",
    "\n",
    "cannot_fix_without_nzsic = current_df[(current_df[\"intended\"].notna()) &\n",
    "    ((current_df[\"difference\"].isna())) &\n",
    "    ( (current_df[\"cmd_1\"].isna()) |\n",
    "      (current_df[\"after_fix_1\"].notna()) & (current_df[\"cmd_2\"].isna()) |\n",
    "      (current_df[\"after_fix_2\"].notna()) & (current_df[\"cmd_3\"].isna()) |\n",
    "      (current_df[\"after_fix_3\"].notna()) & (current_df[\"cmd_4\"].isna()) |\n",
    "      (current_df[\"after_fix_4\"].notna())\n",
    "      )\n",
    "].shape[0]\n",
    "\n",
    "latex_export[\"nb_files_with_errors\"] = total_with_error\n",
    "latex_export[\"nb_were_we_generated_errors\"] = total_with_generation\n",
    "latex_export[\"nb_where_generated_errors_covers_intended\"] = total_where_all_generated\n",
    "latex_export[\"nb_files_with_errors_nnsic\"] = total_with_error_nssic\n",
    "latex_export[\"nb_were_we_generated_errors_nnsic\"] = total_with_generation_nssic\n",
    "latex_export[\"nb_where_generated_errors_covers_intended_nnsic\"] = total_where_all_generated_nssic\n",
    "latex_export[\"errors_type_encountered\"] =  len(set_of_errors)\n",
    "latex_export[\"errors_type_generated\"] =  len(set_of_generation_errors)\n",
    "\n",
    "latex_export[\"case_cannot_be_fixed\"] = cannot_fix_with_nzsic\n",
    "latex_export[\"case_cannot_be_fixed_without_nzic\"] =  cannot_fix_without_nzsic\n",
    "latex_export[\"errors_combination\"] =  len(set(df[df[\"intended\"].notna()][\"intended\"].apply(lambda x: str(x))))\n",
    "latex_export[\"errors_combination_fully_covered\"] =  len(set(df[df[\"difference\"].notna()][\"intended\"].apply(lambda x: str(x))))\n",
    "latex_export[\"errors_combination_covered\"] =  len(set(df[df[\"generated\"].notna()][\"intended\"].apply(lambda x: str(x))))\n"
   ],
   "id": "6f903c5e46f95cac",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Complex DataFrame manipulation\n",
   "id": "cc4ddb69b1bc6890"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### DFixer evaluation (Table 6)",
   "id": "59f0dad8f1816e85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T15:17:35.020924Z",
     "start_time": "2025-08-26T15:17:34.379672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pandas cannot do comparison on lis (non hashable)\n",
    "\n",
    "def str_to_list(l):\n",
    "    res= []\n",
    "\n",
    "    js = json.loads(l.replace(\"'\", '\"'))\n",
    "    for e in js:\n",
    "        res.append(e)\n",
    "\n",
    "    return res\n",
    "\n",
    "current_df = df_not_nzic_only.copy()\n",
    "current_df = current_df[current_df[\"difference\"].isna()]\n",
    "\n",
    "\n",
    "\n",
    "cc1 = Counter(\n",
    "    list(\n",
    "        current_df[(current_df[\"generated\"].notna())& (current_df[\"cmd_1\"].notna())][\"cmd_1\"].apply(lambda x :str_to_list(x)).explode()\n",
    "    )\n",
    ")\n",
    "\n",
    "cc2 = Counter(\n",
    "    list(\n",
    "        current_df[(current_df[\"after_fix_1\"].notna())& (current_df[\"cmd_2\"].notna())][\"cmd_2\"].apply(lambda x :str_to_list(x)).explode()\n",
    "    )\n",
    ")\n",
    "\n",
    "cc3 = Counter(\n",
    "    list(\n",
    "        current_df[(current_df[\"after_fix_2\"].notna())& (current_df[\"cmd_3\"].notna())][\"cmd_3\"].apply(lambda x :str_to_list(x)).explode()\n",
    "    )\n",
    ")\n",
    "\n",
    "cc4 = Counter(\n",
    "    list(\n",
    "        current_df[(current_df[\"after_fix_3\"].notna())& (current_df[\"cmd_4\"].notna())][\"cmd_4\"].apply(lambda x :str_to_list(x)).explode()\n",
    "    )\n",
    ")\n",
    "\n",
    "c1 = dict()\n",
    "nb_c1 = 0\n",
    "for obj in cc1.most_common():\n",
    "    c1[str(obj[0])] = obj[1]\n",
    "    nb_c1 += obj[1]\n",
    "\n",
    "c2 = dict()\n",
    "nb_c2 = 0\n",
    "for obj in cc2.most_common():\n",
    "    c2[str(obj[0])] = obj[1]\n",
    "    nb_c2 += obj[1]\n",
    "\n",
    "c3 = dict()\n",
    "nb_c3 = 0\n",
    "for obj in cc3.most_common():\n",
    "\n",
    "    c3[str(obj[0])] = obj[1]\n",
    "    nb_c3 += obj[1]\n",
    "\n",
    "c4 = dict()\n",
    "nb_c4 = 0\n",
    "for obj in cc4.most_common():\n",
    "    c4[str(obj[0])] = obj[1]\n",
    "    nb_c4 += obj[1]\n",
    "\n",
    "# Select features to show in the table (10 most commons fixes)\n",
    "to_show = set()\n",
    "to_show = to_show.union(set([str(r[0]) for r in  cc1.most_common(10) ]))\n",
    "'''to_show = to_show.union(set([str(r[0]) for r in  cc2.most_common(10) ]))\n",
    "to_show = to_show.union(set([str(r[0]) for r in  cc3.most_common(10) ]))\n",
    "to_show = to_show.union(set([str(r[0]) for r in  cc4.most_common(10) ]))'''\n",
    "#to_show.add(\"nan\")\n",
    "\n",
    "total = set()\n",
    "total = total.union(set([str(r[0] if r[0] is not None or str(r[0]) == \"nan\" else \"nan\") for r in  cc1.most_common() ]))\n",
    "total = total.union(set([str(r[0]) for r in  cc2.most_common() ]))\n",
    "total = total.union(set([str(r[0]) for r in  cc3.most_common() ]))\n",
    "total = total.union(set([str(r[0]) for r in  cc4.most_common() ]))\n",
    "\n",
    "\n",
    "\n",
    "c = {\"cmd_1\": c1, \"cmd_2\": c2, \"cmd_3\": c3, \"cmd_4\": c4}\n",
    "\n",
    "res = dict()\n",
    "\n",
    "other = {\"cmd\" : \"other\", \"cmd_1\": 0 , \"cmd_2\": 0, \"cmd_3\":0, \"cmd_4\":0}\n",
    "for command in [\"cmd_1\", \"cmd_2\", \"cmd_3\", \"cmd_4\"]:\n",
    "    for k in total:\n",
    "        if k not in to_show:\n",
    "            try:\n",
    "                other[command] += c[command].get(k, 0)\n",
    "            except Exception as e:\n",
    "                print()\n",
    "                print(k, e)\n",
    "                raise e\n",
    "        else:\n",
    "            if k not in res :\n",
    "                res[k] = dict()\n",
    "            res[k][command] = c[command].get(k)\n",
    "\n",
    "datas = []\n",
    "for k in res.keys():\n",
    "    tmp = res[k]\n",
    "    if k is None or k == \"nan\":\n",
    "        tmp[\"cmd\"] = \"No command to apply\"\n",
    "    else :\n",
    "        tmp[\"cmd\"] = k\n",
    "    datas.append(tmp)\n",
    "\n",
    "\n",
    "#datas.append({\"cmd\" : \"total\", \"cmd_1\": sc1, \"cmd_2\": sc2, \"cmd_3\": sc3, \"cmd_4\": sc4})\n",
    "#datas.append(other)\n",
    "df2 = pd.DataFrame(datas)\n",
    "df2 = df2.fillna(0)\n",
    "\n",
    "df2.cmd_1 = df2.cmd_1.astype(int)\n",
    "df2.cmd_2 = df2.cmd_2.astype(int)\n",
    "df2.cmd_3 = df2.cmd_3.astype(int)\n",
    "df2.cmd_4 = df2.cmd_4.astype(int)\n",
    "\n",
    "\n",
    "sc1 = df2[\"cmd_1\"].sum()\n",
    "sc2 = df2[\"cmd_2\"].sum()\n",
    "sc3 = df2[\"cmd_3\"].sum()\n",
    "sc4 = df2[\"cmd_4\"].sum()\n",
    "\n",
    "\n",
    "df2[\"c1p\"] = df2[\"cmd_1\"].apply(lambda x : round((x/sc1*100),2) )\n",
    "df2[\"c2p\"] = df2[\"cmd_2\"].apply(lambda x : round((x/sc2*100),2) )\n",
    "df2[\"c3p\"] = df2[\"cmd_3\"].apply(lambda x : round((x/sc3*100),2) )\n",
    "df2[\"c4p\"] = df2[\"cmd_4\"].apply(lambda x : round((x/sc4*100),2) )\n",
    "\n",
    "\n",
    "df2.sort_values(\"cmd_1\", ascending=False, inplace=True)\n",
    "df3 = pd.DataFrame([{\"cmd\" : \"total\", \"cmd_1\": sc1, \"cmd_2\": sc2, \"cmd_3\": sc3, \"cmd_4\": sc4}])\n",
    "df3 = pd.concat([df2, df3])\n",
    "df3.to_csv(\"generated/steps_with_fixes.csv\")\n",
    "\n",
    "print(\"NumberOfStep1 = \" , sc1)\n",
    "print(\"NumberOfStep2 = \" , sc2)\n",
    "print(\"NumberOfStep3 = \" , sc3)\n",
    "print(\"NumberOfStep4 = \" , sc4)\n",
    "latex_export[\"pct_sign_first_iter\"] = list(df3[df3[\"cmd\"] == \"SIGN_ZONE\" ][\"c1p\"])[0]\n",
    "latex_export[\"pct_sign_second_iter\"] = list(df3[df3[\"cmd\"] == \"SIGN_ZONE\" ][\"c2p\"])[0]\n",
    "latex_export[\"pct_sign_third_iter\"] = list(df3[df3[\"cmd\"] == \"SIGN_ZONE\" ][\"c3p\"])[0]\n",
    "latex_export[\"pct_removeds_first_iter\"] = list(df3[df3[\"cmd\"] == \"REMOVE_DS\" ][\"c1p\"])[0]\n",
    "latex_export[\"pct_removeds_second_iter\"] = list(df3[df3[\"cmd\"] == \"REMOVE_DS\" ][\"c2p\"])[0]\n",
    "latex_export[\"pct_removeds_third_iter\"] = list(df3[df3[\"cmd\"] == \"REMOVE_DS\" ][\"c3p\"])[0]\n"
   ],
   "id": "ce1f973c35411a5f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumberOfStep1 =  149773\n",
      "NumberOfStep2 =  15387\n",
      "NumberOfStep3 =  1846\n",
      "NumberOfStep4 =  36\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T15:17:35.039648Z",
     "start_time": "2025-08-26T15:17:35.027902Z"
    }
   },
   "cell_type": "code",
   "source": "df3",
   "id": "4ce066f6aa5bb618",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    cmd_1  cmd_2  cmd_3  cmd_4                 cmd    c1p    c2p    c3p    c4p\n",
       "0   62406  13845   1148      7           SIGN_ZONE  41.67  89.98  62.19  19.44\n",
       "6   46242   1319    668     29           REMOVE_DS  30.87   8.57  36.19  80.56\n",
       "1   14066    117     12      0           UPLOAD_DS   9.39   0.76   0.65   0.00\n",
       "4   13148     83      0      0        GENERATE_KSK   8.78   0.54   0.00   0.00\n",
       "5   11391      0      0      0        SYNC_SERVERS   7.61   0.00   0.00   0.00\n",
       "7    1491      0      0      0        GENERATE_ZSK   1.00   0.00   0.00   0.00\n",
       "2     947      1      0      0        REDUCING_TTL   0.63   0.01   0.00   0.00\n",
       "3      82     22     18      0  REMOVE_REVOKED_KEY   0.05   0.14   0.98   0.00\n",
       "0  149773  15387   1846     36               total    NaN    NaN    NaN    NaN"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cmd_1</th>\n",
       "      <th>cmd_2</th>\n",
       "      <th>cmd_3</th>\n",
       "      <th>cmd_4</th>\n",
       "      <th>cmd</th>\n",
       "      <th>c1p</th>\n",
       "      <th>c2p</th>\n",
       "      <th>c3p</th>\n",
       "      <th>c4p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62406</td>\n",
       "      <td>13845</td>\n",
       "      <td>1148</td>\n",
       "      <td>7</td>\n",
       "      <td>SIGN_ZONE</td>\n",
       "      <td>41.67</td>\n",
       "      <td>89.98</td>\n",
       "      <td>62.19</td>\n",
       "      <td>19.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>46242</td>\n",
       "      <td>1319</td>\n",
       "      <td>668</td>\n",
       "      <td>29</td>\n",
       "      <td>REMOVE_DS</td>\n",
       "      <td>30.87</td>\n",
       "      <td>8.57</td>\n",
       "      <td>36.19</td>\n",
       "      <td>80.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14066</td>\n",
       "      <td>117</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>UPLOAD_DS</td>\n",
       "      <td>9.39</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13148</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GENERATE_KSK</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SYNC_SERVERS</td>\n",
       "      <td>7.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GENERATE_ZSK</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>947</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>REDUCING_TTL</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>REMOVE_REVOKED_KEY</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149773</td>\n",
       "      <td>15387</td>\n",
       "      <td>1846</td>\n",
       "      <td>36</td>\n",
       "      <td>total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Export to the file LaTexData.json for use in DynamicNumbers notebook",
   "id": "d4eef1ed2a673243"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T15:17:35.111904Z",
     "start_time": "2025-08-26T15:17:35.109485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "latex_export[\"nb_line\"] = nb_line\n",
    "\n",
    "with open(\"generated/LaTexData.json\", \"w\") as fp:\n",
    "    json.dump(latex_export, fp, indent=\"    \" )"
   ],
   "id": "87c0258dd8ac2bff",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T15:17:35.155282Z",
     "start_time": "2025-08-26T15:17:35.152188Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "928424139f27f4ec",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
